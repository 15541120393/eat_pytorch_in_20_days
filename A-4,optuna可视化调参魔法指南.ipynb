{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6086209-af84-4acc-9882-96896080051b",
   "metadata": {},
   "source": [
    "# A-4,optuna可视化调参魔法指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f27c",
   "metadata": {},
   "source": [
    "Optuna是一款开源的调参工具，github star数量超过7k, 是目前最受欢迎的调参框架之一。\n",
    "\n",
    "其主要优点如下：\n",
    "\n",
    "1，Optuna拥有许多非常先进的调参算法(如贝叶斯优化，遗传算法采样等)，这些算法往往可以在几十上百次的尝试过程中找到一个不可微问题的较优解。\n",
    "\n",
    "2，通过配合optuna-dashboard，可以可视化整个调参过程，从各个方面加深对问题的理解，这是一个令人心动的特性😋！\n",
    "\n",
    "\n",
    "另外，Optuna还有如下一些非常实用的特性：\n",
    "\n",
    "1，通过将搜索结果存储到sqlite或mysql、postgresql，Optuna支持断点续搜。\n",
    "\n",
    "2，Optuna支持剪枝策略，提前结束一些中间返回结果较差的采样点从而加快搜索进程。\n",
    "\n",
    "3，Optuna支持手动指定一些超参采样点，也可以添加已经计算过的采样点及其结果作为初始化样本点。\n",
    "\n",
    "4，Optuna提供ask and tell 接口模式，无需显式定义目标函数，直接在循环中调优超参。\n",
    "\n",
    "5，Optuna封装了非常丰富的基于plotly的可视化函数，便于分析调参结果。\n",
    "\n",
    "6，通过将搜索结果存储到mysql或postgresql，并设置分布式模式，Optuna支持多机分布式搜索，通过并行方式加快搜索进程。\n",
    "\n",
    "\n",
    "我们将首先展示一些非常实用的综合应用范例演示optuna在算法调优实践中的魔力。\n",
    "\n",
    "然后展示一些optuna的基础特性范例详细讲解optuna的主要特性和API应用方法。\n",
    "\n",
    "\n",
    "综合应用范例：\n",
    "\n",
    "一，optuna对pytorch模型调参范例\n",
    "\n",
    "二，optuna对tensorflow模型调参范例\n",
    "\n",
    "三，optuna对多模型加权融合范例\n",
    "\n",
    "\n",
    "基础特性范例：\n",
    "\n",
    "四，单参数空间搜索范例\n",
    "\n",
    "五，网格参数空间搜索范例\n",
    "\n",
    "六，断点续搜范例\n",
    "\n",
    "七，剪枝策略范例\n",
    "\n",
    "八，各种调参可视化函数范例\n",
    "\n",
    "九，手动添加超参数采样点范例\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef690b43",
   "metadata": {},
   "source": [
    "参考文档\n",
    "\n",
    "optuna官方文档： https://optuna.readthedocs.io/en/stable/tutorial/index.html\n",
    "\n",
    "optuna更多范例库：https://github.com/optuna/optuna-examples 【价值非常大，强烈建议参考】\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f1556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f05b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2464efce",
   "metadata": {},
   "source": [
    "### 〇，环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18914cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install optuna-dashboard -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install plotly -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3965f23",
   "metadata": {},
   "source": [
    "在后台异步执行打开 optuna-dashboard 可视化 监控页面，\n",
    "\n",
    "然后浏览器中输入：http://localhost:8083/dashboard/ 查看监控页面，类似tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16475b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nohup optuna-dashboard --host 0.0.0.0  --port 8083 sqlite:///optuna.db & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88892447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#杀死 optuna-dashboard\n",
    "#!ps aux|grep optuna-dashboard \n",
    "#!kill -9 1161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux|grep optuna-dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d22240",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 2748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bcccf-f945-4678-800f-2d07643d5398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e5912-38fd-4347-807d-54f99757da81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4804599",
   "metadata": {},
   "source": [
    "### 一，optuna对pytorch模型调参范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63ccf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-02 11:12:27,388]\u001b[0m A new study created in RDB with name: fashion_mnist_torch\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:12:36,425]\u001b[0m Trial 0 finished with value: 0.12109375 and parameters: {'n_layers': 1, 'n_units_0': 33, 'dropout_0': 0.20531457816467388, 'optimizer': 'SGD', 'lr': 0.00020073279217809514}. Best is trial 0 with value: 0.12109375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:12:45,756]\u001b[0m Trial 1 finished with value: 0.015625 and parameters: {'n_layers': 1, 'n_units_0': 28, 'dropout_0': 0.4764051188298254, 'optimizer': 'SGD', 'lr': 2.0178216564894824e-05}. Best is trial 0 with value: 0.12109375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:12:57,205]\u001b[0m Trial 2 finished with value: 0.6546875 and parameters: {'n_layers': 1, 'n_units_0': 40, 'dropout_0': 0.14037759456974044, 'optimizer': 'Adam', 'lr': 8.60871937501394e-05}. Best is trial 2 with value: 0.6546875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:08,053]\u001b[0m Trial 3 finished with value: 0.6484375 and parameters: {'n_layers': 3, 'n_units_0': 38, 'dropout_0': 0.37926119391093016, 'n_units_1': 36, 'dropout_1': 0.33599849632612383, 'n_units_2': 57, 'dropout_2': 0.429382635588918, 'optimizer': 'Adam', 'lr': 0.0006834533942776057}. Best is trial 2 with value: 0.6546875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:18,139]\u001b[0m Trial 4 finished with value: 0.746875 and parameters: {'n_layers': 1, 'n_units_0': 33, 'dropout_0': 0.22958726580767908, 'optimizer': 'Adam', 'lr': 0.0005007113308470857}. Best is trial 4 with value: 0.746875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:22,352]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:26,266]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:39,066]\u001b[0m Trial 7 finished with value: 0.81171875 and parameters: {'n_layers': 1, 'n_units_0': 60, 'dropout_0': 0.27690840083718893, 'optimizer': 'Adam', 'lr': 0.014474568880211276}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:51,440]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:12,769]\u001b[0m Trial 9 finished with value: 0.7953125 and parameters: {'n_layers': 2, 'n_units_0': 46, 'dropout_0': 0.2789763876085257, 'n_units_1': 60, 'dropout_1': 0.24080568452657578, 'optimizer': 'Adam', 'lr': 0.0016105658953456323}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:23,161]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:36,389]\u001b[0m Trial 11 finished with value: 0.68046875 and parameters: {'n_layers': 2, 'n_units_0': 19, 'dropout_0': 0.31578402444151393, 'n_units_1': 64, 'dropout_1': 0.1128847476490055, 'optimizer': 'Adam', 'lr': 0.01998175022704327}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:50,747]\u001b[0m Trial 12 finished with value: 0.7625 and parameters: {'n_layers': 3, 'n_units_0': 51, 'dropout_0': 0.423224371640225, 'n_units_1': 60, 'dropout_1': 0.20436751520436375, 'n_units_2': 18, 'dropout_2': 0.11530458917187913, 'optimizer': 'Adam', 'lr': 0.0036209018310348127}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:55,339]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:10,687]\u001b[0m Trial 14 finished with value: 0.76171875 and parameters: {'n_layers': 2, 'n_units_0': 44, 'dropout_0': 0.3123331949410603, 'n_units_1': 47, 'dropout_1': 0.22642603607948086, 'optimizer': 'Adam', 'lr': 0.01390195036980933}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:17,925]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:29,468]\u001b[0m Trial 16 finished with value: 0.81875 and parameters: {'n_layers': 2, 'n_units_0': 58, 'dropout_0': 0.18102784883351564, 'n_units_1': 53, 'dropout_1': 0.11593599889948075, 'optimizer': 'Adam', 'lr': 0.0016479869178747432}. Best is trial 16 with value: 0.81875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:34,123]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:39,098]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:50,590]\u001b[0m Trial 19 finished with value: 0.82734375 and parameters: {'n_layers': 2, 'n_units_0': 57, 'dropout_0': 0.10186665202462081, 'n_units_1': 53, 'dropout_1': 0.38459041401832517, 'optimizer': 'Adam', 'lr': 0.007727434890198083}. Best is trial 19 with value: 0.82734375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.82734375\n",
      "best_params:\n",
      "{'dropout_0': 0.10186665202462081, 'dropout_1': 0.38459041401832517, 'lr': 0.007727434890198083, 'n_layers': 2, 'n_units_0': 57, 'n_units_1': 53, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_{}\".format(i), 16, 64)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        \n",
    "        #attention here \n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=3), direction=\"maximize\",\n",
    "        study_name=\"fashion_mnist_torch\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=20, timeout=1200)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b92d7",
   "metadata": {},
   "source": [
    "![](https://p.ipic.vip/4fjrpv.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6987bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7a1147",
   "metadata": {},
   "source": [
    "### 二，optuna对tensorflow模型调参范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3031fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-02 11:07:56,295]\u001b[0m A new study created in RDB with name: mnist-tf\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:02,793]\u001b[0m Trial 0 finished with value: 0.12600000202655792 and parameters: {'n_layers': 3, 'n_units_0': 42, 'dropout_0': 0.28984103665666494, 'n_units_1': 39, 'dropout_1': 0.2603956381566199, 'n_units_2': 5, 'dropout_2': 0.2557919509084582, 'learning_rate': 0.043984526529105235}. Best is trial 0 with value: 0.12600000202655792.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:07,465]\u001b[0m Trial 1 finished with value: 0.8799999952316284 and parameters: {'n_layers': 1, 'n_units_0': 32, 'dropout_0': 0.15469731865044578, 'learning_rate': 0.01845450781604031}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:13,867]\u001b[0m Trial 2 finished with value: 0.781000018119812 and parameters: {'n_layers': 3, 'n_units_0': 19, 'dropout_0': 0.11448373690608848, 'n_units_1': 27, 'dropout_1': 0.34349713407049337, 'n_units_2': 13, 'dropout_2': 0.4170670510656864, 'learning_rate': 0.02153707314303828}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:18,318]\u001b[0m Trial 3 finished with value: 0.6399999856948853 and parameters: {'n_layers': 2, 'n_units_0': 7, 'dropout_0': 0.3149109532566708, 'n_units_1': 34, 'dropout_1': 0.21675495761949304, 'learning_rate': 0.011811988149809969}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:24,295]\u001b[0m Trial 4 finished with value: 0.5049999952316284 and parameters: {'n_layers': 3, 'n_units_0': 6, 'dropout_0': 0.2267345387858625, 'n_units_1': 11, 'dropout_1': 0.4695925079219597, 'n_units_2': 28, 'dropout_2': 0.4009393810562977, 'learning_rate': 0.0005079052014906984}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:28,042]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:33,562]\u001b[0m Trial 6 finished with value: 0.8830000162124634 and parameters: {'n_layers': 2, 'n_units_0': 51, 'dropout_0': 0.41858653169684945, 'n_units_1': 47, 'dropout_1': 0.3302950378535904, 'learning_rate': 0.00505482940342642}. Best is trial 6 with value: 0.8830000162124634.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:37,449]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:42,384]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:47,582]\u001b[0m Trial 9 finished with value: 0.8920000195503235 and parameters: {'n_layers': 1, 'n_units_0': 29, 'dropout_0': 0.19122436741466836, 'learning_rate': 0.007698814404681437}. Best is trial 9 with value: 0.8920000195503235.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:52,558]\u001b[0m Trial 10 finished with value: 0.8510000109672546 and parameters: {'n_layers': 1, 'n_units_0': 17, 'dropout_0': 0.4766819949314297, 'learning_rate': 0.0015224565276997705}. Best is trial 9 with value: 0.8920000195503235.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:57,762]\u001b[0m Trial 11 finished with value: 0.9049999713897705 and parameters: {'n_layers': 1, 'n_units_0': 62, 'dropout_0': 0.45611973124885824, 'learning_rate': 0.003504024162733378}. Best is trial 11 with value: 0.9049999713897705.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:02,464]\u001b[0m Trial 12 finished with value: 0.9079999923706055 and parameters: {'n_layers': 1, 'n_units_0': 59, 'dropout_0': 0.22384888955958546, 'learning_rate': 0.0024974162743369756}. Best is trial 12 with value: 0.9079999923706055.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:06,532]\u001b[0m Trial 13 finished with value: 0.8889999985694885 and parameters: {'n_layers': 1, 'n_units_0': 62, 'dropout_0': 0.4964493759229309, 'learning_rate': 0.0007854601822750143}. Best is trial 12 with value: 0.9079999923706055.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:10,860]\u001b[0m Trial 14 finished with value: 0.906000018119812 and parameters: {'n_layers': 1, 'n_units_0': 64, 'dropout_0': 0.24928045309792424, 'learning_rate': 0.0021728199859401918}. Best is trial 12 with value: 0.9079999923706055.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:13,891]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:16,810]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:19,932]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:23,064]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:26,487]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.9079999923706055\n",
      "best_params:\n",
      "{'dropout_0': 0.22384888955958546, 'learning_rate': 0.0024974162743369756, 'n_layers': 1, 'n_units_0': 59}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_{}\".format(i), 4, 64, log=True)\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        model.add(layers.Dropout(rate=dropout))\n",
    "    model.add(layers.Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "    (x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)[:N_TRAIN_EXAMPLES].astype(\"float32\") / 255\n",
    "    x_valid = x_valid.reshape(10000, 784)[:N_VALID_EXAMPLES].astype(\"float32\") / 255\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = to_categorical(y_train[:N_TRAIN_EXAMPLES], CLASSES)\n",
    "    y_valid = to_categorical(y_valid[:N_VALID_EXAMPLES], CLASSES)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCHSIZE,\n",
    "        callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-tf\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aa6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2642555",
   "metadata": {},
   "source": [
    "### 三，optuna对多模型加权融合范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497e262",
   "metadata": {},
   "source": [
    "多模型加权融合是一个常见的提升机器学习效果的方案。\n",
    "\n",
    "但是各个模型的权重如何确定呢？\n",
    "\n",
    "有些方案是使用线性回归或者逻辑回归模型进行学习，这种方案一般叫做stacking ensemble，但是这种方案一般是对可微的Loss进行优化的，无法直接对auc,acc等不可微的评价指标进行优化。\n",
    "\n",
    "由于optuna是一个强大的不可微问题调优工具，我们可以使用它来寻找模型融合的权重，直接对auc,acc等不可微的评价指标进行优化，当给予足够的搜索次数时，其结果相比stacking ensemble通常更加有竞争力。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90d5ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "# 一，准备数据\n",
    "data,target = make_classification(n_samples=2000,n_features=20,\n",
    "        n_informative=12,n_redundant=4,n_repeated=0,n_classes=2,\n",
    "        n_clusters_per_class=4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c21c2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 二，训练3个基础模型\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "mlp = MLPClassifier()\n",
    "svc = SVC(probability=True) \n",
    "\n",
    "mlp.fit(x_train,y_train)\n",
    "tree.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "737d582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_score: 0.9381438344093945\n",
      "tree_score: 0.7036158861885002\n",
      "svc_score: 0.9356125538698153\n"
     ]
    }
   ],
   "source": [
    "# 三，评估单模型效果\n",
    "def get_test_auc(model):\n",
    "    probs = model.predict_proba(x_test)[:,1]\n",
    "    val_auc = roc_auc_score(y_test,probs)\n",
    "    return val_auc\n",
    "\n",
    "print(\"mlp_score:\",get_test_auc(mlp))\n",
    "print(\"tree_score:\",get_test_auc(tree))\n",
    "print(\"svc_score:\",get_test_auc(svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f52f16f5-7fdd-4f74-aa61-a2ab2f4302be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking_score: 0.9440074336339896\n"
     ]
    }
   ],
   "source": [
    "# 四， stacking方案效果\n",
    "from sklearn.ensemble import StackingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[('mlp',mlp),('tree',tree),('svc',svc)],\n",
    "    final_estimator=LogisticRegression())\n",
    "stacking.fit(x_train,y_train)\n",
    "print(\"stacking_score:\",get_test_auc(stacking))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21f7cb-7a4d-4151-adb3-7db3788cd9aa",
   "metadata": {},
   "source": [
    "![](./data/stacking融合.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda6f57-9b49-4057-a97a-c72980f5ad61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77b0fdaf-28be-45d1-9336-a9149145219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 五，获取CV预测结果\n",
    "\n",
    "# 为了充分利用训练数据集，采用类似stacking的方式，用5折CV的方式获取各个模型在训练集的预测结果\n",
    "\n",
    "def get_cv_preds(model,x_train,y_train):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    cv_preds = np.zeros(len(y_train))\n",
    "    \n",
    "    for idx, (train_idx, valid_idx) in enumerate(cv.split(x_train, y_train)):\n",
    "        xtrain_i, xvalid_i = x_train[train_idx], x_train[valid_idx]\n",
    "        ytrain_i, yvalid_i = y_train[train_idx], y_train[valid_idx]\n",
    "        model_idx = deepcopy(model)\n",
    "        model_idx.fit(xtrain_i,ytrain_i)\n",
    "        probs_valid_idx = model_idx.predict_proba(xvalid_i)[:,1]\n",
    "        cv_preds[valid_idx] = probs_valid_idx\n",
    "    return cv_preds\n",
    "\n",
    "preds_cv = {name: get_cv_preds(eval(name),x_train,y_train)\n",
    "             for name in ['mlp','tree','svc']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba4b770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.9685616736555074\n",
      "best_params:\n",
      "{'mlp': 51, 'svc': 98, 'tree': 1}\n"
     ]
    }
   ],
   "source": [
    "# 六， optuna搜索融合权重\n",
    "\n",
    "import optuna \n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial):\n",
    "    weights = {name:trial.suggest_int(name, 1, 100) for name in ['mlp','tree','svc']}\n",
    "    probs = sum([weights[name]*preds_cv[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    \n",
    "    cv_auc = roc_auc_score(y_train,probs)\n",
    "    trial.report(cv_auc, 0)\n",
    "    return cv_auc\n",
    "\n",
    "storage_name = \"sqlite:///optuna.db\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"optuna_ensemble\", storage=storage_name,load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=500, timeout=600)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aaa37176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_ensemble_score: 0.9441195789743508\n"
     ]
    }
   ],
   "source": [
    "# 七， optuna权重融合效果\n",
    "preds_test = {name:(eval(name)).predict_proba(x_test)[:,1] for name in ['mlp','tree','svc']}\n",
    "def test_score(weights):\n",
    "    probs = sum([weights[name]*preds_test[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    test_auc = roc_auc_score(y_test,probs)\n",
    "    return test_auc\n",
    "print('optuna_ensemble_score:',test_score(best_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a57d09-7571-4bc9-829b-542b7a77741c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85997229",
   "metadata": {},
   "source": [
    "比单模型的最优值svc的得分(0.9690)有些许提升。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d4223-3f11-4cea-91df-eb41d5af382c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca2f39-5b5d-4351-8c4b-b9e4a09c97a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5235ea-d5f8-41dd-84d4-fbf8d2ad826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28fe42-055c-49d3-91d9-f468d331c4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2ff21-db88-4982-a639-fe9170db5136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa8b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2443798c",
   "metadata": {},
   "source": [
    "以下范例为基础特性范例讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4e9eb",
   "metadata": {},
   "source": [
    "### 四，单参数空间搜索范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b19f3",
   "metadata": {},
   "source": [
    "Optuna支持的调参算法主要包括以下这些：\n",
    "\n",
    "```\n",
    "optuna.samplers.GridSampler(网格搜索采样)\n",
    "optuna.samplers.RandomSampler(随机搜索采样)\n",
    "optuna.samplers.TPESampler(贝叶斯优化采样)\n",
    "optuna.samplers.NSGAIISampler(遗传算法采样)\n",
    "optuna.samplers.CmaEsSampler(协方差矩阵自适应演化策略采样，非常先进的优化算法)\n",
    "```\n",
    "\n",
    "此外，还可以用以下方法将部分超参固定，仅对其它一些参数进行超参优化。\n",
    "```\n",
    "optuna.samplers.PartialFixedSampler(部分参数固定采样算法)\n",
    "```\n",
    "\n",
    "可以在optuna.create_study时候用sampler参数指定。\n",
    "\n",
    "如果不指定的话，一般在单目标优化算法中，使用的是optuna.samplers.TPESampler调参算法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088930c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import optuna\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, 定义目标函数\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# 2, 执行搜索过程\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.CmaEsSampler(),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"simple_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=1000,show_progress_bar = True)\n",
    "\n",
    "# 3, 获取最优超参\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, 绘制搜索过程\n",
    "\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500,log_y=True)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe93047",
   "metadata": {},
   "source": [
    "```\n",
    "best_value = 0.0013535850035239266\n",
    "best_params:\n",
    "{'x': 2.0367910995150176}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3befc61",
   "metadata": {},
   "source": [
    "![](https://p.ipic.vip/cq006d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730afa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6986e39a",
   "metadata": {},
   "source": [
    "### 五，网格参数空间搜索范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef7eac",
   "metadata": {},
   "source": [
    "多个参数可以用字典表述成网格参数空间形式。\n",
    "\n",
    "optuna支持各种各样的输入参数类型。常见的有以下一些\n",
    "\n",
    "``` python\n",
    "trail = optuna.trial.Trial\n",
    "trail.suggest_categorical\n",
    "trail.suggest_discrete_uniform\n",
    "trail.suggest_float\n",
    "trail.suggest_int\n",
    "trail.suggest_loguniform\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f497ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import optuna \n",
    "\n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, 定义目标函数\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -1, 1)\n",
    "    f = trial.suggest_categorical(\"f\",['sin','sinh','cos','cosh'])\n",
    "    dic = {'sin':np.sin,'cos':np.cos,'sinh':np.sinh,'cosh':np.cosh}\n",
    "    fn = dic[f]\n",
    "    return fn(x)\n",
    "\n",
    "\n",
    "# 2, 执行搜索过程\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(seed=123),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"grid_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=100,show_progress_bar = True)\n",
    "\n",
    "# 3, 获取最优超参\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, 绘制搜索过程\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "display(dftrials)\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e593c3",
   "metadata": {},
   "source": [
    "### 六，断点续搜范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55235ae4",
   "metadata": {},
   "source": [
    "有时候超参搜索过程中有可能中间机器会死掉，可以使用sqlite/mysql等存储方式存储搜索结果到数据库文件。\n",
    "\n",
    "这样便可以读取历史搜索结果，继续搜索。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# 1, 定义目标函数\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "# 2, 执行搜索过程\n",
    "study_name = \"example-study\"  \n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "#period0\n",
    "study0 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study0.optimize(objective, n_trials=10)\n",
    "\n",
    "#period1\n",
    "study1 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study1.optimize(objective, n_trials=10)\n",
    "\n",
    "#period2\n",
    "study2 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "dftrials = study2.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "\n",
    "# 3, 获取最优超参\n",
    "best_params = study2.best_params\n",
    "best_value = study2.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "display(dftrials)\n",
    "\n",
    "\n",
    "# 4, 绘制搜索过程\n",
    "fig = optuna.visualization.plot_optimization_history(study2)\n",
    "#fig.layout.yaxis.type = 'log'\n",
    "fig.update_layout({\"yaxis.type\":\"log\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd117eda",
   "metadata": {},
   "source": [
    "### 七，剪枝策略范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89458262",
   "metadata": {},
   "source": [
    "optuna支持多种剪枝策略，如果某个超参采样点返回的中间结果和之前采样点相比表现得没有希望，optuna可以提前结束这个采样点的训练，从而节约时间。\n",
    "\n",
    "* optuna.pruners.HyperbandPruner: pruner refers to http://www.jmlr.org/papers/volume18/16-558/16-558.pdf\n",
    "\n",
    "* optuna.pruners.MedianPruner: Prune if the trial's best intermediate result is worse than median of intermediate results of previous trials at the same step.\n",
    "\n",
    "* optuna.pruners.ThresholdPruner: Pruner to detect outlying metrics of the trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646efdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    plot_optimization_history(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c095c9f",
   "metadata": {},
   "source": [
    "### 八，各种调参可视化函数范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    # Visualize the optimization history.\n",
    "    plot_optimization_history(study).show()\n",
    "\n",
    "    # Visualize the learning curves of the trials.\n",
    "    plot_intermediate_values(study).show()\n",
    "\n",
    "    # Visualize high-dimensional parameter relationships.\n",
    "    plot_parallel_coordinate(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_parallel_coordinate(study, params=[\"lr_init\", \"n_units_l0\"]).show()\n",
    "\n",
    "    # Visualize hyperparameter relationships.\n",
    "    plot_contour(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_contour(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
    "\n",
    "    # Visualize individual hyperparameters.\n",
    "    plot_slice(study).show()\n",
    "\n",
    "    # Select parameter\n",
    "    # Visualize parameter importances.\n",
    "    plot_param_importances(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4c1362",
   "metadata": {},
   "source": [
    "### 九，手动添加超参数采样点范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d9658",
   "metadata": {},
   "source": [
    "有时候，我们在使用特定的采样算法之前，想尝试一些人工指定的超参采样点，在Optuna中我们可以用\n",
    "\n",
    "study.enqueue_trial 将这些人工指定超参采样点推入测试队列。\n",
    "\n",
    "另外，如果我们已经手动执行了一些超参采样点，并获得了结果，我们可以用 study.add_trail的方法\n",
    "\n",
    "将这些结果添加到已评估的超参采样点列表中。后续的超参数采样将会考虑这些采样点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a790e2",
   "metadata": {},
   "source": [
    "**1，指定手工采样点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e60c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 1.0,\n",
    "        \"bagging_freq\": 0,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 0.75,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Add stream handler of stdout to show the messages to see Optuna works expectedly.\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9102e",
   "metadata": {},
   "source": [
    "**2，添加已评估采样点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7da213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 1.0,\n",
    "            \"bagging_freq\": 0,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.94,\n",
    "    )\n",
    ")\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 0.75,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.95,\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
