{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6086209-af84-4acc-9882-96896080051b",
   "metadata": {},
   "source": [
    "# A-4,optuna可视化调参魔法指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f27c",
   "metadata": {},
   "source": [
    "Optuna是一款开源的调参工具，github star数量超过7k, 是目前最受欢迎的调参框架之一。\n",
    "\n",
    "其主要优点如下：\n",
    "\n",
    "1，Optuna拥有许多非常先进的调参算法(如贝叶斯优化，遗传算法采样等)，这些算法往往可以在几十上百次的尝试过程中找到一个不可微问题的较优解。\n",
    "\n",
    "2，通过配合optuna-dashboard，可以可视化整个调参过程，从各个方面加深对问题的理解，这是一个令人心动的特性😋！\n",
    "\n",
    "\n",
    "另外，Optuna还有如下一些非常实用的特性：\n",
    "\n",
    "1，通过将搜索结果存储到sqlite或mysql、postgresql，Optuna支持断点续搜。\n",
    "\n",
    "2，Optuna支持剪枝策略，提前结束一些中间返回结果较差的采样点从而加快搜索进程。\n",
    "\n",
    "3，Optuna支持手动指定一些超参采样点，也可以添加已经计算过的采样点及其结果作为初始化样本点。\n",
    "\n",
    "4，Optuna提供ask and tell 接口模式，无需显式定义目标函数，直接在循环中调优超参。\n",
    "\n",
    "5，Optuna封装了非常丰富的基于plotly的可视化函数，便于分析调参结果。\n",
    "\n",
    "6，通过将搜索结果存储到mysql或postgresql，并设置分布式模式，Optuna支持多机分布式搜索，通过并行方式加快搜索进程。\n",
    "\n",
    "\n",
    "我们将首先展示一些非常实用的综合应用范例演示optuna在算法调优实践中的魔力。\n",
    "\n",
    "然后展示一些optuna的基础特性范例详细讲解optuna的主要特性和API应用方法。\n",
    "\n",
    "\n",
    "综合应用范例：\n",
    "\n",
    "一，optuna对pytorch模型调参范例\n",
    "\n",
    "二，optuna对tensorflow模型调参范例\n",
    "\n",
    "三，optuna对多模型加权融合范例\n",
    "\n",
    "\n",
    "基础特性范例：\n",
    "\n",
    "四，单参数空间搜索范例\n",
    "\n",
    "五，网格参数空间搜索范例\n",
    "\n",
    "六，断点续搜范例\n",
    "\n",
    "七，剪枝策略范例\n",
    "\n",
    "八，各种调参可视化函数范例\n",
    "\n",
    "九，手动添加超参数采样点范例\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef690b43",
   "metadata": {},
   "source": [
    "参考文档\n",
    "\n",
    "optuna官方文档： https://optuna.readthedocs.io/en/stable/tutorial/index.html\n",
    "\n",
    "optuna更多范例库：https://github.com/optuna/optuna-examples 【价值非常大，强烈建议参考】\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f1556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f05b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2464efce",
   "metadata": {},
   "source": [
    "### 〇，环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18914cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install optuna-dashboard -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install plotly -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3965f23",
   "metadata": {},
   "source": [
    "在后台异步执行打开 optuna-dashboard 可视化 监控页面，\n",
    "\n",
    "然后浏览器中输入：http://localhost:8083/ 查看监控页面，类似tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16475b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nohup optuna-dashboard --host 0.0.0.0  --port 8083 sqlite:///optuna.db & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88892447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#杀死 optuna-dashboard\n",
    "#!ps aux|grep optuna-dashboard \n",
    "#!kill -9 1161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux|grep optuna-dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d22240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4804599",
   "metadata": {},
   "source": [
    "### 一，optuna对pytorch模型调参范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ccf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_{}\".format(i), 4, 64)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        \n",
    "        #attention here \n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-torch\", storage=storage_name,load_if_exists=False\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7a1147",
   "metadata": {},
   "source": [
    "### 二，optuna对tensorflow模型调参范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3031fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_{}\".format(i), 4, 64, log=True)\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        model.add(layers.Dropout(rate=dropout))\n",
    "    model.add(layers.Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "    (x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)[:N_TRAIN_EXAMPLES].astype(\"float32\") / 255\n",
    "    x_valid = x_valid.reshape(10000, 784)[:N_VALID_EXAMPLES].astype(\"float32\") / 255\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = to_categorical(y_train[:N_TRAIN_EXAMPLES], CLASSES)\n",
    "    y_valid = to_categorical(y_valid[:N_VALID_EXAMPLES], CLASSES)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCHSIZE,\n",
    "        callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-tf\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aa6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2642555",
   "metadata": {},
   "source": [
    "### 三，optuna对多模型加权融合范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "data,target = make_classification(n_samples=2000,n_features=20,\n",
    "        n_informative=12,n_redundant=4,n_repeated=0,n_classes=2,\n",
    "        n_clusters_per_class=4)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "mlp = MLPClassifier()\n",
    "svc = SVC(probability=True) \n",
    "\n",
    "\n",
    "mlp.fit(x_train,y_train)\n",
    "tree.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "def get_val_auc(model):\n",
    "    probs = model.predict_proba(x_valid)[:,1]\n",
    "    val_auc = roc_auc_score(y_valid,probs)\n",
    "    return val_auc\n",
    "\n",
    "print(\"mlp_score:\",get_val_auc(mlp))\n",
    "print(\"tree_score:\",get_val_auc(tree))\n",
    "print(\"svc_score:\",get_val_auc(svc))\n",
    "\n",
    "\n",
    "preds_val = {name:(eval(name)).predict_proba(x_valid)[:,1] for name in ['mlp','tree','svc']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "\n",
    "def objective(trial):\n",
    "    weights = {name:trial.suggest_int(name, 1, 100) for name in ['mlp','tree','svc']}\n",
    "    probs = sum([weights[name]*preds_val[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    \n",
    "    val_auc = roc_auc_score(y_valid,probs)\n",
    "    trial.report(val_auc, 0)\n",
    "    return val_auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=\"ensemble\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e17174-a141-4184-96b8-041c3e4fc8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2443798c",
   "metadata": {},
   "source": [
    "以下范例为基础特性范例讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4e9eb",
   "metadata": {},
   "source": [
    "### 四，单参数空间搜索范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b19f3",
   "metadata": {},
   "source": [
    "Optuna支持的调参算法主要包括以下这些：\n",
    "\n",
    "```\n",
    "optuna.samplers.GridSampler(网格搜索采样)\n",
    "optuna.samplers.RandomSampler(随机搜索采样)\n",
    "optuna.samplers.TPESampler(贝叶斯优化采样)\n",
    "optuna.samplers.NSGAIISampler(遗传算法采样)\n",
    "optuna.samplers.CmaEsSampler(协方差矩阵自适应演化策略采样，非常先进的优化算法)\n",
    "```\n",
    "\n",
    "此外，还可以用以下方法将部分超参固定，仅对其它一些参数进行超参优化。\n",
    "```\n",
    "optuna.samplers.PartialFixedSampler(部分参数固定采样算法)\n",
    "```\n",
    "\n",
    "可以在optuna.create_study时候用sampler参数指定。\n",
    "\n",
    "如果不指定的话，一般在单目标优化算法中，使用的是optuna.samplers.TPESampler调参算法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088930c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import optuna\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, 定义目标函数\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# 2, 执行搜索过程\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.CmaEsSampler(),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"simple_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=1000,show_progress_bar = True)\n",
    "\n",
    "# 3, 获取最优超参\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, 绘制搜索过程\n",
    "\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500,log_y=True)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986e39a",
   "metadata": {},
   "source": [
    "### 五，网格参数空间搜索范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef7eac",
   "metadata": {},
   "source": [
    "多个参数可以用字典表述成网格参数空间形式。\n",
    "\n",
    "optuna支持各种各样的输入参数类型。常见的有以下一些\n",
    "\n",
    "``` python\n",
    "trail = optuna.trial.Trial\n",
    "trail.suggest_categorical\n",
    "trail.suggest_discrete_uniform\n",
    "trail.suggest_float\n",
    "trail.suggest_int\n",
    "trail.suggest_loguniform\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f497ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import optuna \n",
    "\n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, 定义目标函数\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -1, 1)\n",
    "    f = trial.suggest_categorical(\"f\",['sin','sinh','cos','cosh'])\n",
    "    dic = {'sin':np.sin,'cos':np.cos,'sinh':np.sinh,'cosh':np.cosh}\n",
    "    fn = dic[f]\n",
    "    return fn(x)\n",
    "\n",
    "\n",
    "# 2, 执行搜索过程\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(seed=123),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"grid_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=100,show_progress_bar = True)\n",
    "\n",
    "# 3, 获取最优超参\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, 绘制搜索过程\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "display(dftrials)\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e593c3",
   "metadata": {},
   "source": [
    "### 六，断点续搜范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55235ae4",
   "metadata": {},
   "source": [
    "有时候超参搜索过程中有可能中间机器会死掉，可以使用sqlite/mysql等存储方式存储搜索结果到数据库文件。\n",
    "\n",
    "这样便可以读取历史搜索结果，继续搜索。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# 1, 定义目标函数\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "# 2, 执行搜索过程\n",
    "study_name = \"example-study\"  \n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "#period0\n",
    "study0 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study0.optimize(objective, n_trials=10)\n",
    "\n",
    "#period1\n",
    "study1 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study1.optimize(objective, n_trials=10)\n",
    "\n",
    "#period2\n",
    "study2 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "dftrials = study2.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "\n",
    "# 3, 获取最优超参\n",
    "best_params = study2.best_params\n",
    "best_value = study2.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "display(dftrials)\n",
    "\n",
    "\n",
    "# 4, 绘制搜索过程\n",
    "fig = optuna.visualization.plot_optimization_history(study2)\n",
    "#fig.layout.yaxis.type = 'log'\n",
    "fig.update_layout({\"yaxis.type\":\"log\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd117eda",
   "metadata": {},
   "source": [
    "### 七，剪枝策略范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89458262",
   "metadata": {},
   "source": [
    "optuna支持多种剪枝策略，如果某个超参采样点返回的中间结果和之前采样点相比表现得没有希望，optuna可以提前结束这个采样点的训练，从而节约时间。\n",
    "\n",
    "* optuna.pruners.HyperbandPruner: pruner refers to http://www.jmlr.org/papers/volume18/16-558/16-558.pdf\n",
    "\n",
    "* optuna.pruners.MedianPruner: Prune if the trial's best intermediate result is worse than median of intermediate results of previous trials at the same step.\n",
    "\n",
    "* optuna.pruners.ThresholdPruner: Pruner to detect outlying metrics of the trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646efdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    plot_optimization_history(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c095c9f",
   "metadata": {},
   "source": [
    "### 八，各种调参可视化函数范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    # Visualize the optimization history.\n",
    "    plot_optimization_history(study).show()\n",
    "\n",
    "    # Visualize the learning curves of the trials.\n",
    "    plot_intermediate_values(study).show()\n",
    "\n",
    "    # Visualize high-dimensional parameter relationships.\n",
    "    plot_parallel_coordinate(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_parallel_coordinate(study, params=[\"lr_init\", \"n_units_l0\"]).show()\n",
    "\n",
    "    # Visualize hyperparameter relationships.\n",
    "    plot_contour(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_contour(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
    "\n",
    "    # Visualize individual hyperparameters.\n",
    "    plot_slice(study).show()\n",
    "\n",
    "    # Select parameter\n",
    "    # Visualize parameter importances.\n",
    "    plot_param_importances(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4c1362",
   "metadata": {},
   "source": [
    "### 九，手动添加超参数采样点范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d9658",
   "metadata": {},
   "source": [
    "有时候，我们在使用特定的采样算法之前，想尝试一些人工指定的超参采样点，在Optuna中我们可以用\n",
    "\n",
    "study.enqueue_trial 将这些人工指定超参采样点推入测试队列。\n",
    "\n",
    "另外，如果我们已经手动执行了一些超参采样点，并获得了结果，我们可以用 study.add_trail的方法\n",
    "\n",
    "将这些结果添加到已评估的超参采样点列表中。后续的超参数采样将会考虑这些采样点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a790e2",
   "metadata": {},
   "source": [
    "**1，指定手工采样点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e60c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 1.0,\n",
    "        \"bagging_freq\": 0,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 0.75,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Add stream handler of stdout to show the messages to see Optuna works expectedly.\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9102e",
   "metadata": {},
   "source": [
    "**2，添加已评估采样点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7da213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 1.0,\n",
    "            \"bagging_freq\": 0,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.94,\n",
    "    )\n",
    ")\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 0.75,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.95,\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
