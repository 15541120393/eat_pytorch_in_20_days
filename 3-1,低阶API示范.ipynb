{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8428e0",
   "metadata": {},
   "source": [
    "# 3-1,低阶API示范\n",
    "\n",
    "下面的范例使用Pytorch的低阶API实现线性回归模型和DNN二分类模型。\n",
    "\n",
    "低阶API主要包括张量操作，计算图和自动微分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "#打印时间\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ec15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print(\"torch.__version__=\"+torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c5a1d",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__=1.10.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd55a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "361ef742",
   "metadata": {},
   "source": [
    "### 一，线性回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba6e5f",
   "metadata": {},
   "source": [
    "**1，准备数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e278470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "#样本数量\n",
    "n = 400\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = 10*torch.rand([n,2])-5.0  #torch.rand是均匀分布 \n",
    "w0 = torch.tensor([[2.0],[-3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "Y = X@w0 + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @表示矩阵乘法,增加正态扰动\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.scatter(X[:,0].numpy(),Y[:,0].numpy(), c = \"b\",label = \"samples\")\n",
    "ax1.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\",rotation = 0)\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(X[:,1].numpy(),Y[:,0].numpy(), c = \"g\",label = \"samples\")\n",
    "ax2.legend()\n",
    "plt.xlabel(\"x2\")\n",
    "plt.ylabel(\"y\",rotation = 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a94d4e",
   "metadata": {},
   "source": [
    "![](./data/3-1-回归数据可视化.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据管道迭代器\n",
    "def data_iter(features, labels, batch_size=8):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    np.random.shuffle(indices)  #样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        indexs = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield  features.index_select(0, indexs), labels.index_select(0, indexs)\n",
    "        \n",
    "# 测试数据管道效果   \n",
    "batch_size = 8\n",
    "(features,labels) = next(data_iter(X,Y,batch_size))\n",
    "print(features)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43310a",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[-4.3880,  1.3655],\n",
    "        [-0.1082,  3.9533],\n",
    "        [-2.6286,  2.7058],\n",
    "        [ 1.0604, -1.8646],\n",
    "        [-1.5805,  1.5406],\n",
    "        [-2.6217, -3.2342],\n",
    "        [ 2.3748, -0.6449],\n",
    "        [-1.2478, -2.0509]])\n",
    "tensor([[-0.2069],\n",
    "        [-3.2494],\n",
    "        [-6.9620],\n",
    "        [17.0528],\n",
    "        [ 1.1076],\n",
    "        [17.2117],\n",
    "        [16.1081],\n",
    "        [14.7092]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599a732",
   "metadata": {},
   "source": [
    "**2，定义模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a27738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class LinearRegression: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w = torch.randn_like(w0,requires_grad=True)\n",
    "        self.b = torch.zeros_like(b0,requires_grad=True)\n",
    "        \n",
    "    #正向传播\n",
    "    def forward(self,x): \n",
    "        return x@self.w + self.b\n",
    "\n",
    "    # 损失函数\n",
    "    def loss_fn(self,y_pred,y_true):  \n",
    "        return torch.mean((y_pred - y_true)**2/2)\n",
    "\n",
    "model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08deb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd7e8da",
   "metadata": {},
   "source": [
    "**3，训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fece800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, features, labels):\n",
    "    \n",
    "    predictions = model.forward(features)\n",
    "    loss = model.loss_fn(predictions,labels)\n",
    "        \n",
    "    # 反向传播求梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 使用torch.no_grad()避免梯度记录，也可以通过操作 model.w.data 实现避免梯度记录 \n",
    "    with torch.no_grad():\n",
    "        # 梯度下降法更新参数\n",
    "        model.w -= 0.001*model.w.grad\n",
    "        model.b -= 0.001*model.b.grad\n",
    "\n",
    "        # 梯度清零\n",
    "        model.w.grad.zero_()\n",
    "        model.b.grad.zero_()\n",
    "    return loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试train_step效果\n",
    "batch_size = 10\n",
    "(features,labels) = next(data_iter(X,Y,batch_size))\n",
    "train_step(model,features,labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e8941",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(92.8199, grad_fn=<MeanBackward0>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273af6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,epochs):\n",
    "    for epoch in range(1,epochs+1):\n",
    "        for features, labels in data_iter(X,Y,10):\n",
    "            loss = train_step(model,features,labels)\n",
    "\n",
    "        if epoch%200==0:\n",
    "            printbar()\n",
    "            print(\"epoch =\",epoch,\"loss = \",loss.item())\n",
    "            print(\"model.w =\",model.w.data)\n",
    "            print(\"model.b =\",model.b.data)\n",
    "\n",
    "train_model(model,epochs = 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe039f",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2020-07-05 08:27:57\n",
    "epoch = 200 loss =  2.6340413093566895\n",
    "model.w = tensor([[ 2.0283],\n",
    "        [-2.9632]])\n",
    "model.b = tensor([[10.0748]])\n",
    "\n",
    "================================================================================2020-07-05 08:28:00\n",
    "epoch = 400 loss =  2.24908709526062\n",
    "model.w = tensor([[ 2.0300],\n",
    "        [-2.9643]])\n",
    "model.b = tensor([[10.0781]])\n",
    "\n",
    "================================================================================2020-07-05 08:28:04\n",
    "epoch = 600 loss =  1.510349154472351\n",
    "model.w = tensor([[ 2.0290],\n",
    "        [-2.9630]])\n",
    "model.b = tensor([[10.0781]])\n",
    "\n",
    "================================================================================2020-07-05 08:28:07\n",
    "epoch = 800 loss =  1.038671851158142\n",
    "model.w = tensor([[ 2.0314],\n",
    "        [-2.9649]])\n",
    "model.b = tensor([[10.0785]])\n",
    "\n",
    "================================================================================2020-07-05 08:28:10\n",
    "epoch = 1000 loss =  1.9742190837860107\n",
    "model.w = tensor([[ 2.0313],\n",
    "        [-2.9648]])\n",
    "model.b = tensor([[10.0781]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abfa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果可视化\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.scatter(X[:,0].numpy(),Y[:,0].numpy(), c = \"b\",label = \"samples\")\n",
    "ax1.plot(X[:,0].numpy(),(model.w[0].data*X[:,0]+model.b[0].data).numpy(),\"-r\",linewidth = 5.0,label = \"model\")\n",
    "ax1.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\",rotation = 0)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(X[:,1].numpy(),Y[:,0].numpy(), c = \"g\",label = \"samples\")\n",
    "ax2.plot(X[:,1].numpy(),(model.w[1].data*X[:,1]+model.b[0].data).numpy(),\"-r\",linewidth = 5.0,label = \"model\")\n",
    "ax2.legend()\n",
    "plt.xlabel(\"x2\")\n",
    "plt.ylabel(\"y\",rotation = 0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b5823",
   "metadata": {},
   "source": [
    "![](./data/3-1-回归结果可视化.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83a9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "946c733c",
   "metadata": {},
   "source": [
    "### 二，DNN二分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33bef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e9b2a60",
   "metadata": {},
   "source": [
    "**1，准备数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#正负样本数量\n",
    "n_positive,n_negative = 2000,2000\n",
    "\n",
    "#生成正样本, 小圆环分布\n",
    "r_p = 5.0 + torch.normal(0.0,1.0,size = [n_positive,1]) \n",
    "theta_p = 2*np.pi*torch.rand([n_positive,1])\n",
    "Xp = torch.cat([r_p*torch.cos(theta_p),r_p*torch.sin(theta_p)],axis = 1)\n",
    "Yp = torch.ones_like(r_p)\n",
    "\n",
    "#生成负样本, 大圆环分布\n",
    "r_n = 8.0 + torch.normal(0.0,1.0,size = [n_negative,1]) \n",
    "theta_n = 2*np.pi*torch.rand([n_negative,1])\n",
    "Xn = torch.cat([r_n*torch.cos(theta_n),r_n*torch.sin(theta_n)],axis = 1)\n",
    "Yn = torch.zeros_like(r_n)\n",
    "\n",
    "#汇总样本\n",
    "X = torch.cat([Xp,Xn],axis = 0)\n",
    "Y = torch.cat([Yp,Yn],axis = 0)\n",
    "\n",
    "\n",
    "#可视化\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\n",
    "plt.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\n",
    "plt.legend([\"positive\",\"negative\"]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe69467",
   "metadata": {},
   "source": [
    "![](./data/3-1-分类数据可视化.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ed2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据管道迭代器\n",
    "def data_iter(features, labels, batch_size=8):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    np.random.shuffle(indices)  #样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        indexs = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield  features.index_select(0, indexs), labels.index_select(0, indexs)\n",
    "        \n",
    "# 测试数据管道效果   \n",
    "batch_size = 8\n",
    "(features,labels) = next(data_iter(X,Y,batch_size))\n",
    "print(features)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df9bd0",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 6.9914, -1.0820],\n",
    "        [ 4.8156,  4.0532],\n",
    "        [-1.0697, -7.4644],\n",
    "        [ 2.6291,  3.8851],\n",
    "        [-1.6780, -4.3390],\n",
    "        [-6.1495,  1.2269],\n",
    "        [-4.3422,  3.9552],\n",
    "        [-6.2265,  2.6159]])\n",
    "tensor([[0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bafa46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3131995",
   "metadata": {},
   "source": [
    "**2，定义模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f2a11e",
   "metadata": {},
   "source": [
    "此处范例我们利用nn.Module来组织模型变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.w1 = nn.Parameter(torch.randn(2,4))\n",
    "        self.b1 = nn.Parameter(torch.zeros(1,4))\n",
    "        self.w2 = nn.Parameter(torch.randn(4,8))\n",
    "        self.b2 = nn.Parameter(torch.zeros(1,8))\n",
    "        self.w3 = nn.Parameter(torch.randn(8,1))\n",
    "        self.b3 = nn.Parameter(torch.zeros(1,1))\n",
    "\n",
    "    # 正向传播\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(x@self.w1 + self.b1)\n",
    "        x = torch.relu(x@self.w2 + self.b2)\n",
    "        y = torch.sigmoid(x@self.w3 + self.b3)\n",
    "        return y\n",
    "    \n",
    "    # 损失函数(二元交叉熵)\n",
    "    def loss_fn(self,y_pred,y_true):  \n",
    "        #将预测值限制在1e-7以上, 1- (1e-7)以下，避免log(0)错误\n",
    "        eps = 1e-7\n",
    "        y_pred = torch.clamp(y_pred,eps,1.0-eps)\n",
    "        bce = - y_true*torch.log(y_pred) - (1-y_true)*torch.log(1-y_pred)\n",
    "        return torch.mean(bce)\n",
    "    \n",
    "    # 评估指标(准确率)\n",
    "    def metric_fn(self,y_pred,y_true):\n",
    "        y_pred = torch.where(y_pred>0.5,torch.ones_like(y_pred,dtype = torch.float32),\n",
    "                          torch.zeros_like(y_pred,dtype = torch.float32))\n",
    "        acc = torch.mean(1-torch.abs(y_true-y_pred))\n",
    "        return acc\n",
    "    \n",
    "model = DNNModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型结构\n",
    "batch_size = 10\n",
    "(features,labels) = next(data_iter(X,Y,batch_size))\n",
    "\n",
    "predictions = model(features)\n",
    "\n",
    "loss = model.loss_fn(labels,predictions)\n",
    "metric = model.metric_fn(labels,predictions)\n",
    "\n",
    "print(\"init loss:\", loss.item())\n",
    "print(\"init metric:\", metric.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e9356",
   "metadata": {},
   "source": [
    "```\n",
    "init loss: 7.979694366455078\n",
    "init metric: 0.50347900390625\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05475551",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d3815",
   "metadata": {},
   "source": [
    "```\n",
    "6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0c58c",
   "metadata": {},
   "source": [
    "**3，训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, features, labels):   \n",
    "    \n",
    "    # 正向传播求损失\n",
    "    predictions = model.forward(features)\n",
    "    loss = model.loss_fn(predictions,labels)\n",
    "    metric = model.metric_fn(predictions,labels)\n",
    "        \n",
    "    # 反向传播求梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 梯度下降法更新参数\n",
    "    for param in model.parameters():\n",
    "        #注意是对param.data进行重新赋值,避免此处操作引起梯度记录\n",
    "        param.data = (param.data - 0.01*param.grad.data) \n",
    "        \n",
    "    # 梯度清零\n",
    "    model.zero_grad()\n",
    "        \n",
    "    return loss.item(),metric.item()\n",
    " \n",
    "\n",
    "def train_model(model,epochs):\n",
    "    for epoch in range(1,epochs+1):\n",
    "        loss_list,metric_list = [],[]\n",
    "        for features, labels in data_iter(X,Y,20):\n",
    "            lossi,metrici = train_step(model,features,labels)\n",
    "            loss_list.append(lossi)\n",
    "            metric_list.append(metrici)\n",
    "        loss = np.mean(loss_list)\n",
    "        metric = np.mean(metric_list)\n",
    "\n",
    "        if epoch%100==0:\n",
    "            printbar()\n",
    "            print(\"epoch =\",epoch,\"loss = \",loss,\"metric = \",metric)\n",
    "        \n",
    "train_model(model,epochs = 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ba034e",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2020-07-05 08:32:16\n",
    "epoch = 100 loss =  0.24841043589636683 metric =  0.8944999960064888\n",
    "\n",
    "================================================================================2020-07-05 08:32:34\n",
    "epoch = 200 loss =  0.20398724960163236 metric =  0.920999992787838\n",
    "\n",
    "================================================================================2020-07-05 08:32:54\n",
    "epoch = 300 loss =  0.19509393003769218 metric =  0.9239999914169311\n",
    "\n",
    "================================================================================2020-07-05 08:33:14\n",
    "epoch = 400 loss =  0.19067603485658766 metric =  0.9272499939799309\n",
    "\n",
    "================================================================================2020-07-05 08:33:33\n",
    "epoch = 500 loss =  0.1898010154720396 metric =  0.9237499925494194\n",
    "\n",
    "================================================================================2020-07-05 08:33:54\n",
    "epoch = 600 loss =  0.19151576517149807 metric =  0.9254999926686287\n",
    "\n",
    "================================================================================2020-07-05 08:34:18\n",
    "epoch = 700 loss =  0.18914461021777243 metric =  0.9274999949336052\n",
    "\n",
    "================================================================================2020-07-05 08:34:39\n",
    "epoch = 800 loss =  0.18801998342387377 metric =  0.9264999932050705\n",
    "\n",
    "================================================================================2020-07-05 08:35:00\n",
    "epoch = 900 loss =  0.1852504052128643 metric =  0.9249999937415123\n",
    "\n",
    "================================================================================2020-07-05 08:35:21\n",
    "epoch = 1000 loss =  0.18695520935580134 metric =  0.9272499927878379\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果可视化\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize = (12,5))\n",
    "ax1.scatter(Xp[:,0],Xp[:,1], c=\"r\")\n",
    "ax1.scatter(Xn[:,0],Xn[:,1],c = \"g\")\n",
    "ax1.legend([\"positive\",\"negative\"]);\n",
    "ax1.set_title(\"y_true\");\n",
    "\n",
    "Xp_pred = X[torch.squeeze(model.forward(X)>=0.5)]\n",
    "Xn_pred = X[torch.squeeze(model.forward(X)<0.5)]\n",
    "\n",
    "ax2.scatter(Xp_pred[:,0],Xp_pred[:,1],c = \"r\")\n",
    "ax2.scatter(Xn_pred[:,0],Xn_pred[:,1],c = \"g\")\n",
    "ax2.legend([\"positive\",\"negative\"]);\n",
    "ax2.set_title(\"y_pred\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2bdb3",
   "metadata": {},
   "source": [
    "![](./data/3-1-分类结果可视化.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28395ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d3200d6",
   "metadata": {},
   "source": [
    "**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n",
    "\n",
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![算法美食屋logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
